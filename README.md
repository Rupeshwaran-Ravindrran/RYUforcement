# Reinforcement Learning in Street Fighter

Welcome to our Reinforcement Learning (RL) project focused on mastering Street Fighter using cutting-edge techniques in Python. This project utilizes the powerful combination of gym-retro for game emulation, Optuna for hyperparameter optimization, and Stable Baselines3 for RL model creation.

## Overview

In this project, we aim to train RL agents to excel in Street Fighter gameplay through repeated interactions and learning from experience. By leveraging the gym-retro environment, we can simulate Street Fighter matches and train our agents to make optimal decisions in real-time combat scenarios.

## Key Features

- **gym-retro Integration:** Utilize gym-retro's extensive library of retro games, including Street Fighter, for realistic game emulation.
- **Optuna Hyperparameter Optimization:** Fine-tune model hyperparameters automatically with Optuna, maximizing performance.
- **Stable Baselines3 Models:** Implement state-of-the-art RL algorithms from Stable Baselines3 to train robust agents.
- **Customizable Training Environment:** Easily modify training parameters and game settings to explore different strategies and scenarios.
- **Visualizations and Analysis:** Visualize training progress, analyze agent behavior, and track performance metrics for informed decision-making.

## Getting Started

1. Clone the repository to your local machine.
2. Install the required dependencies using `pip install -r requirements.txt`.
3. Follow the instructions in the documentation to set up the environment and start training your RL agents.

## Contributions

Contributions to this project are welcome! Whether you're interested in adding new features, optimizing algorithms, or improving documentation, we appreciate any contributions that help advance the capabilities of our RL agents in Street Fighter.

## License

This project is licensed under the [MIT License](LICENSE), allowing for open collaboration and usage.
